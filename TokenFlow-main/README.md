# ðŸŒ± TokenFlow â€” Optimize Prompts. Save Tokens. Protect the Planet.

**TokenFlow** is a privacy-first Chrome extension that rewrites your AI prompts *locally* before theyâ€™re sent to models like ChatGPT, Claude, or Gemini. Using **winkNLP** and semantic heuristics, it eliminates filler, sharpens clarity, and reduces token countâ€”cutting down the environmental footprint of every interaction.

> âš¡ Run faster, cost less, and do goodâ€”without changing your workflow.

---

## ðŸš€ Features

- âœ… **Automatic Prompt Optimization**  
  Silently intercepts and rewrites your prompts with smarter, cleaner phrasing.

- âœ… **Shallow Semantic Compression**  
  Uses NLP (winkNLP) and in-browser heuristics to remove redundancy while preserving intent.

- âœ… **Instant Token Savings Feedback**  
  Get real-time stats on how many tokens you saved after every prompt.

- âœ… **Sensitive Data Masking**  
  Automatically masks API keys, passwords, and secrets with `****`.

- âœ… **Sustainability Impact Tracking**  
  Tracks estimated reductions in:  
  âš¡ Electricity (kWh)  
  ðŸ’§ Water (litres)  
  ðŸŒ Carbon (gCOâ‚‚)

- âœ… **Full Privacy. Zero APIs.**  
  All processing is done 100% locally inside the browserâ€”no servers, no tracking.

- âœ… **Impact Dashboard**  
  View cumulative stats on your eco-savings over time.

---

## ðŸ“¸ Demo

Coming soon 

---

## ðŸ§  How It Works

1. **Prompt Detection**  
   Listens for prompts on ChatGPT, Claude, Gemini, etc., without altering UI.

2. **In-Browser NLP Optimization**  
   Applies winkNLP and semantic heuristics to compress and clean the prompt.

3. **Token Comparison Engine**  
   Calculates the token difference between the original and optimized prompt.

4. **Toast Notification**  
   After sending, shows token savings and environmental impact.

5. **Dashboard Display**  
   Tracks total tokens saved, water and energy conserved, and COâ‚‚ avoided.

---

## ðŸ›  Tech Stack

- **Browser**: Chrome Extension (Manifest V3)  
- **Language**: TypeScript  
- **Build Tool**: Vite  
- **UI**: Tailwind CSS v4.1 + [shadcn/ui](https://ui.shadcn.com)  
- **NLP Engine**: [winkNLP](https://winkjs.org)  
- **Storage**: Chrome Local Storage  
- **Runtime**: 100% offline, WASM-free (no model inference required)

---

## ðŸ” Privacy First

TokenFlow processes everything **locally** inside your browser.  
No prompts are sent to external servers. No tracking. No analytics.  
Your data stays yours.

---

## ðŸ§ª Use Cases

- ðŸ§‘â€ðŸ’» Developers avoiding prompt bloat in ChatGPT  
- ðŸ“µ Journalists working with sensitive data  
- ðŸ§‘â€âš– Legal researchers prioritizing privacy  
- ðŸ§‘â€ðŸ« Educators and students learning sustainable AI  
- ðŸ¢ Organizations measuring eco-impact from LLM usage  

---

## ðŸŒ Why TokenFlow?

Every LLM prompt consumes:

- âš¡ Electricity (to run models)
- ðŸ’§ Water (for data center cooling)
- ðŸŒ Carbon (indirect emissions)

Cutting just a few tokens per promptâ€”at scaleâ€”saves:

- Thousands of litres of water  
- Kilowatt-hours of electricity  
- Measurable COâ‚‚ emissions

> TokenFlow helps you reduce compute load, improve model speed, and use AI more responsibly.


